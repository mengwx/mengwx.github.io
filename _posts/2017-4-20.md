---
layout: post
title:  "DNCs 结构梳理"
category: notes
author: "孟文霞"

---

## 1. DNC结构
* 两大部分：Controller(neural network)、Memory(M × N Matrix)
* 三个 Mechanisms：Content lookup、 Temporal links 和 Allocation
* 一个 Temporal matrix：L(N × N)
* 一个 Temporal link：Usage
* 读相关的控制向量：Read weighting(W<sup>r</sup>)
* 写相关的控制向量：Write weighting(W<sup>w</sup>)、Erase vector(e)、write vector(v)

Mechanisms 的实现对应的 Vector 和 Matrix 如下图：    

![3](/images/blog/2017-4-20/3.jpg)  


## 2. DNC 与传统计算机
![1](/images/blog/2017-4-20/1.jpg)  

### 2.1 Controller 与 CPU 区别：
* Controller 通过 gradient descent 进行学习
* Controller 是一个 neural network.

### 2.2 Memory 的特点：
* Memory can be selectively written to as well as read
* Memory allowing iterative modification of memory content.

### 2.3 Address:
* Conventional computers:unique addresses to access memory contents.
* DNC:有不同的方式来访问 matrix M 。 

#### 2.3.1 DNC Address 设置
weightings:表示每一个 location 被读或者写的程度。

##### 2.3.1.1 Read heads:
* Read weighting:W<sup>r</sup> 

##### 2.3.1.2 Write heads:
* Write weighting:W<sup>w</sup>
* Erase vector:e
* write vector:v


### 2.4 DNC 与 Neural Turing Machine
有着相似的结构，但是 Neural Turing Machine 在 memory access methods 方面表现不如 DNC。    

## 3. Heads 和 Memory 交互的三种机制

### 3.1 Content lookup
通过比较 controller 发出的 vector 和每个 location content 的 cos 值，来决定对内存中内容的读和写的权限。(当这个匹配值较小时仍然可以进行一定程度的读写操作)

### 3.2 Temporal links 
通过一个 N × N temporal link matrix L 来实现。     
#### L[i,j] 值的确定：
L[i,j] is close to 1 if i was the next location written after j, and is close to 0 otherwise.    . 

#### 3.2.1 Temporal links 实现的功能：
* Forward： Lw
* Backwards：L<sup>⊤</sup>w 

能够通过找到哪一个向量对 Memory 进行写操作，来进行数据的 Forward 和 Backwards 操作，来实现对数据操作过程的记录和再现。

### 3.3 Allocation 
each location 有一个 ‘usage’的值，这个值在0-1之间，这个数字会在 location 的内容被使用时降低，不使用的时候自动增加。这样就能帮助 DNC 找到不常用或者当前没有被使用的地址来使用。


## 4. 我的想法
* Controller 用一个 neural network 难以实现传统操作系统中程序的 调度(多个CPU或核)/切换(一个CPU给多个程序使用)功能，是不是可以把 Controller 扩充为多个 neutral network.    
* 多个进程/线程共同执行时，怎么解决进程之间内存隔离的问题，地址直接的权限关系怎么设置。
* 多个进程/线程共同执行时，怎么实现进程之间的通讯问题。
