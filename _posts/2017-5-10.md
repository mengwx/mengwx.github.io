--- 
layout: post 
title: "TensorFlow Programmer's Guide"        
category: notes
author: "孟文霞" 

--- 

**TensorFlow安装**：[[https://www.tensorflow.org/install/]](https://www.tensorflow.org/install/)    
### 注意事项
* Python 要选择3.5版本(Anaconda自带Python)
* 用命令行下载 TensorFlow 时可能会因为网站被墙而下载失败，我现在常用的翻墙方式有三种：
* 1.自己搭建了 VPS 服务器，用 shadowsocks 翻墙
* 2.更改 host 文件穿墙
* 3.Lantern 软件翻墙
* 安装时下载失败只能选择第 3. 种方式翻墙，前两种无效。

## TensorFlow基本语法

### Variables：Creation, Initialization, Saving, and Loading
**Creation**：`tf.Variable()`    
**注意**：You need to specify the shape of the tensors, but TensorFlow provides advanced mechanisms to reshape variables.    

```python
	weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),
      	                name="weights")
	biases = tf.Variable(tf.zeros([200]), name="biases")
```

weights 的类型为     
`<tf.Variable 'weights:0' shape=(784, 200) dtype=float32_ref>`    

变量可以通过 `with tf.device()` 函数被 pinned 到一个固定的设备上：    

```python
	with tf.device("/cpu:0"):
		v = tf.Variable(...)
	with tf.device("/gpu:0"):
		v = tf.Variable(...)
	with tf.device("/job:ps/task:7"):
		v = tf.Variable(...)
```

其中 0 为第一块，1 为第二块(GPU)，以此类推，也可以被 pinned 到一个特定的 server task 上。    

**说明**：tf.Variable.assign 和 tf.train.Optimizer 执行时要和 variable 在一个设备上，否则函数会被忽略。

**Initialization**:全局初始化：`tf.global_variables_initializer()`    


Variable 在使用前必须进行 initialize。    

```python
	init_op = tf.global_variables_initializer()
	with tf.Session() as sess:
		sess.run(init_op)
```

单个初始化`initialized_value()`
`w2 = tf.Variable(weights.initialized_value(), name="w2")`    

**Saving and Restoring**: 保存：`tf.train.Saver` 恢复使用时不需要 initialize 
        
    


### Tensor Ranks, Shapes, and Types
TensorFlow 中存储数据的形式是 Tensor(张量,见高算第2.部分)，官方文档中说可以把 Tensor(张量)理解为 an n-dimensional array or list. A tensor has a static type and dynamic dimensions. Only tensors may be passed between nodes in the computation graph.    

**Rank**：Tensor rank (sometimes referred to as order or degree or n-dimension) is the number of dimensions of the tensor. 例如如下在 Python 中定义的 rank 值为 2 ：    
`t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]`    
Tensor 在某些情况下可以理解为数据的维数。 1 rank 的 Tensor 可以理解为向量，2 rank 的 Tensor 可以理解为矩阵，用 `t[i,j]`来进行定位，三 rank 的用 `t[i,j,k]`。     

![1](/assets/img/1.png)  

**Shape**:Rank, shape, and dimension number 三者的关系如图，可以用 Python 的 lists/tuples 来定义，也可以用 `tf.TensorShape` 来定义。     
![2](/assets/img/2.png)     

**Data types**:`tf.float32` 也包括 int string unit bool 等类型。

### Sharing Variables   
在需要大规模共享 Variables 时，可以通过 `tf.variable_scope()` 统一使用和 initialize，通过 `tf.get_variable()` 来获得 Variables.    

```python
	variables_dict = {
    	"conv1_weights": tf.Variable(tf.random_normal([5, 5, 32, 32]),
			name="conv1_weights")
		"conv1_biases": tf.Variable(tf.zeros([32]), name="conv1_biases")
    		... etc. ...
	}
	def my_image_filter(input_images, variables_dict):
		conv1 = tf.nn.conv2d(input_images, variables_dict["conv1_weights"],
    	    strides=[1, 1, 1, 1], padding='SAME')
		relu1 = tf.nn.relu(conv1 + variables_dict["conv1_biases"])
		conv2 = tf.nn.conv2d(relu1, variables_dict["conv2_weights"],
			strides=[1, 1, 1, 1], padding='SAME')
		return tf.nn.relu(conv2 + variables_dict["conv2_biases"])
	# Both calls to my_image_filter() now use the same variables
	result1 = my_image_filter(image1, variables_dict)
	result2 = my_image_filter(image2, variables_dict)
```

可以通过 dict 来保存 tf.Variable 然后写成函数来使多组数据共享一组参数。

#### Variable Scope Example(常用于CNN)
* tf.get_variable(<name>, <shape>, <initializer>): Creates or returns a variable with a given name.(获取已有的变量，内含参数 initialize，注意 tf.Variable 需要单独写 initialize 函数)
* tf.variable\_scope(<scope\_name>): Manages namespaces for names passed to tf.get_variable().

#### initialize 的三种常用方式
* tf.constant_initializer(value) initializes everything to the provided value,
* tf.random\_uniform_initializer(a, b) initializes uniformly from [a, b],
* tf.random\_normal_initializer(mean, stddev) initializes from the normal distribution with the given mean and standard deviation.      

代码如下：    
```python
	def conv_relu(input, kernel_shape, bias_shape):
		weights = tf.get_variable("weights", kernel_shape,
			initializer=tf.random_normal_initializer())
		biases = tf.get_variable("biases", bias_shape,
			initializer=tf.constant_initializer(0.0))
		conv = tf.nn.conv2d(input, weights,
			strides=[1, 1, 1, 1], padding='SAME')
		return tf.nn.relu(conv + biases)
```

同名变量的命名空间，定义函数：`tf.variable_scope()`，不同命名空间域的变量互相获取变量值需要使用函数：`tf.get_variable()`
```python
	def my_image_filter(input_images):
	    with tf.variable_scope("conv1"):
	        # Variables created here will be named "conv1/weights", "conv1/biases".
	        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])
	    with tf.variable_scope("conv2"):
	        # Variables created here will be named "conv2/weights", "conv2/biases".
	        return conv_relu(relu1, [5, 5, 32, 32], [32])
```

命名空间重用：In this case, the call will search for an already existing variable with name equal to the current variable scope name + the provided name. If no such variable exists, a ValueError will be raised. If the variable is found, it will be returned. For example.    
```python
	with tf.variable_scope("foo"):
	    v = tf.get_variable("v", [1])
	with tf.variable_scope("foo", reuse=True):
	    v1 = tf.get_variable("v", [1])
	assert v1 is v
```

另一种写法也可以实现不同命名空间下的变量重用：    
```python
	with tf.variable_scope("foo"):
	    v = tf.get_variable("v", [1])
	    tf.get_variable_scope().reuse_variables()
	    v1 = tf.get_variable("v", [1])
	assert v1 is v
```

对引用来的其他命名空间的变量进行 initialize，可以通过调用函数时候的参数来进行，如下：    
```python
	with tf.variable_scope("foo", initializer=tf.constant_initializer(0.4)):
	    v = tf.get_variable("v", [1])
	    assert v.eval() == 0.4  # Default initializer as set above.
	    w = tf.get_variable("w", [1], initializer=tf.constant_initializer(0.3)):
	    assert w.eval() == 0.3  # Specific initializer overrides the default.
	    with tf.variable_scope("bar"):
	        v = tf.get_variable("v", [1])
	        assert v.eval() == 0.4  # Inherited default initializer.
	    with tf.variable_scope("baz", initializer=tf.constant_initializer(0.2)):
	        v = tf.get_variable("v", [1])
	        assert v.eval() == 0.2  # Changed default initializer.
```

### Threading and Queues 
TensoFlow 提供 Queues 的操作方式，具体细节可以在需要用到的时候再返回来查询。Queues 是 TensorFlow 进行同步计算的重要机制，Queues 在图中是一个结点，详见：    
[[https://www.tensorflow.org/programmers_guide/threading_and_queues]](https://www.tensorflow.org/programmers_guide/threading_and_queues)     

#### 多线程
TensorFlow provides two classes to help: tf.train.Coordinator and tf.train.QueueRunner. These two classes are designed to be used together. The Coordinator class helps multiple threads stop together and report exceptions to a program that waits for them to stop. The QueueRunner class is used to create a number of threads cooperating to enqueue tensors in the same queue.    
   

### Reading data
#### TensorFlow 的三种读取数据的方式：
* Feeding: Python code provides the data when running each step.
* Reading from files: an input pipeline reads the data from files **at the beginning of a TensorFlow graph**.
* Preloaded data: a constant or variable in the TensorFlow graph holds all the data (for small data sets).

1.Feeding：通过 feed_dict 来传入参数。    
```python
	with tf.Session():
	  input = tf.placeholder(tf.float32)
	  classifier = ...
	  print(classifier.eval(feed_dict={input: my_python_preprocessing_fn()}))
```

建议使用 `tf.placeholder` 不需要初始化，但是没有赋值的话会自动报错。A placeholder exists solely to serve as the target of feeds. It is not initialized and contains no data. A placeholder generates an error if it is executed without a feed, so you won't forget to feed it.    

从文档中都数据的步骤如下：
* The list of filenames
* Optional filename shuffling
* Optional epoch limit
* Filename queue
* A Reader for the file format
* A decoder for a record read by the reader
* Optional preprocessing
* Example queue

### 读.csv文档 
```python
	# -*- coding: utf-8 -*-
	from __future__ import unicode_literals
	import tensorflow as tf
	filename_queue = tf.train.string_input_producer(["file0.csv"])
	reader = tf.TextLineReader()
	key, value = reader.read(filename_queue)
	# Default values, in case of empty columns. Also specifies the type of the
	# decoded result.
	record_defaults = [[1], [1], [1]]
	# 这里用[1.0]就表示对应位置的数字是 float32 型
	# 但是貌似如果是 int 就要求都是 int, 如果 float32 都是 float32, 不同数据类型交叉着使用会报错
	col1, col2, col3 = tf.decode_csv(
	    value, record_defaults=record_defaults)
	features = tf.stack([col1, col2])
	with tf.Session() as sess:
	  # Start populating the filename queue.
	  coord = tf.train.Coordinator()
	  threads = tf.train.start_queue_runners(coord=coord)
	  for i in range(15):
	    # Retrieve a single instance:
	    example, label = sess.run([features, col3])
	    # 打印 Tensor 的值，直接 print 打印出来的是数据类型
	    print(sess.run([col1, col2, col3]))
	  coord.request_stop()
	  coord.join(threads)
```

至此，TensorFlow 的数据类型定义、初始化、读取已经初步介绍完毕，其中多线程的部分可以在需要处理大规模数据时再返回来查询，Programmer's Guide 阅读完毕。
